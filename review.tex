\documentclass{article} \title{Automomous Control of Aircraft for
  Communications and Electronic Warfare: The Promises of Recent
  Artifical Intelligence Literature}
\author{Sean Carver, Ph.D. at Data Machines Corporation}
\begin{document}
\maketitle
\abstract{We pose an unsolved problem in autonomous control of
  aircraft for communications and jamming (electronic warfare) and
  review the literature relevant to this problem. Some work offers
  approximately optimal solutions to related problems in different
  domains---promising applicability to the important scenarios
  considered here.  Other work covers methods that we may find useful
  in extending these relevant solutions.
  
  The problem we address lies within the fields of adversarial
  Multi-Agent Reinforcement Learning (MARL) and active sensing.  In
  our problem, two opposing factions (labeled ``blue'' and ``red'')
  compete to win a zero-sum/purely adversarial game.  The blue side
  tries to maintain communication links between ground-based assets
  with a fleet of ``comms;'' whereas the red side tries to jam this
  network with a fleet of ``jammers.''  An Unmanned Aerial Vehicle
  (UAV) becomes a comm or a jammer when fitted for one of these
  purposes.

  Each faction lacks access to the state of the opposing side, and
  must infer this state probabilisticly through positioning its fleet
  for best sensory performance and localization (active sensing).
  Moreover, the ground troops of each side, when also positioned
  appropriately, have the possibility of shooting down any of their
  adversary's UAVs.  The blue side must simultaneously achieve its
  objective of keeping units on the ground in communication and the
  red side must simultaneously try to jam this communication.  Despite
  best efforts, different units/UAVs can fall in and out of
  communication with their respective headquarters, making each of the
  blue and red factions a multi-agent collection, fully cooperating
  among itself, but with different information, to fight its adversary
  having opposing goals.

  Our contribution poses this problem while pointing to literature for
  possible ideas for moving the field forward.  We discuss the use of
  a heirarchy of simpler-than-reality mini-games for efficiently
  investigating and building upon solutions leading to a successful
  implementation for the full adversarial problem in real-world
  combat.}

\section{Introduction}

If unfortunate circumstances compel our leaders to order our armed
forces to take a city from an adversary, the command headquarters on
the ground would benefit from constant two-way communication with all
its other units during the conflict.

In the fog that accompanies such struggles, our forces cannot rely on
our enemy's network of cell towers to keep in touch.  Instead, two way
radios, linked by a network of ``comms'' (UAVs for communication) will
hopefully allow our friendlies to stay connected.

While vastly better than cell phones, such a network has it own set of
challenges.  Indeed, our adversaries clearly prefer to keep us out of
communication.  To pursue this preference, they may send up jammers
(UAVs for blocking communication).  Thus begins a delicate dance of
each side positioning its fleet to best find the other's birds and in
so doing best keep or block communications.

We study the question of how each side can control its fleet by
autonomously ordering and carrying out flight and communications-
electronics operation instructions (CEOI) to optimally achieve its
objectives.  We are interested in the strategies for both sides,
because to defeat our enemy, we must understand the intelligent
countermeasures they may take. Moreover, in a real war, our side---as
well as theirs---may choose to fly both comms and jammers, requiring
strategies for both roles.

Much recent literature has tackled the problem of optimal search and
rescue.  Other work has considered different scenarios requiring
similar tools---notably cyber-security and precision farming.  CITE 3.
Search and rescue clearly relates to the problem at hand because, as
with rescue, each of our sides benefits from successfully inferring
the positions of targets.  But there is a difference between search
and rescue and electronic warfare.  People being rescued presumably
want to be found and will presumably cooperate with this effort.  In
electronic warfare, on the other hand, participants always aim to keep
their locations hidden from the other side. As a result, while search
and rescue can succeed with a purely active sensing and optimal
control solution, in our scenario, we need to learn to counter an
opponent's strategy.  To this end, we propose to apply artificial
intelligence: specifically, adversarial multi-agent reinforcement
learning. This paper reviews the literature relevant to this approach
to electronic warfare.

\section{Optimal and suboptimal filtering}
The filtering problem takes measurements of a stochastic
system---possibly transformed measurements and possibly with
noise---and produces estimates of the state of the system.

Readers will find the optimal solution to this problem in the first
pages of any textbook CITE on nonlinear filtering: a recursion
consisting of alternating applications of the Chapman-Kolmogorov
Equation and Bayes Rule.

Unfortunately, solving each of these equations demands an integration
which remains impossible to perform exactly (ie without
discretizatiom) in all but two cases.  In all other cases, a
researcher must use an approximation---a suboptimal (hopefully
approximately optimal) filter.  Readers will find that the rest of the
nonlinear filtering textbooks (beyond the first few pages devoted to
the optimal exposition) concerns these suboptimal approximations.

We list the two optimal solutions to the filtering equation as (1) the
Kalman filter, and (2) the hidden Markov filter.  The Kalman filter
applies with a linear model of the process, a quadratic objective
function measuring optimality, and Gaussian noise corruption (both the
process noise and the measurement noise).  On the other hand, a hidden
Markov filter applies with a finite-state model of the process. These
restrictions unacceptably constrain usable models for our application
area, and therefore we will focus on approximately optimal
alternatives.

Several specific approximations merit mention.  An extended Kalman
filter linearizes the state space around each sample point allowing
the calculations behind the Kalman filter to proceed. The
approximation works well when the optimal distributions for state
remain close to Gaussian.  If they do not, the Extended Kalman Filter
can perform poorly.  A second approximation, a grid-based filter,
approximates the state space with a finite grid of points allowing the
calculations behind a hidden (finite) Markov filter to proceed.  A
grid-based filter works well for the lowest dimensional state spaces,
but becomes intractable when the dimensions becomes even slightly
higher.  In preliminary investigations of the main problem that
motivated this review [reseach paper in prepapration], one and two
targets worked well (each adding two dimensions to the state), whereas
three targets did not.

Particle filtering

\section{Active sensing}

\section{Reinforcement Learning}

\nocite{*}
\bibliographystyle{ieeetr}
% \bibliographystyle{unsrt}
\bibliography{marl}

\end{document}
